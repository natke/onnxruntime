<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `onnxruntime/src/download/vision/object_detection_image_segmentation.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>object_detection_image_segmentation.rs - source</title><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/SourceSerif4-Regular-1f7d512b176f0f72.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/FiraSans-Regular-018c141bf0843ffd.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/FiraSans-Medium-8f9a781e4970d388.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/SourceCodePro-Regular-562dcc5011b6de7d.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/SourceSerif4-Bold-124a1ca42af929b6.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../static.files/SourceCodePro-Semibold-d899c5a5c4aeb14a.ttf.woff2"><link rel="stylesheet" href="../../../../static.files/normalize-76eba96aa4d2e634.css"><link rel="stylesheet" href="../../../../static.files/rustdoc-6827029ac823cab7.css" id="mainThemeStyle"><link rel="stylesheet" id="themeStyle" href="../../../../static.files/light-ebce58d0a40c3431.css"><link rel="stylesheet" disabled href="../../../../static.files/dark-f23faae4a2daf9a6.css"><link rel="stylesheet" disabled href="../../../../static.files/ayu-8af5e100b21cd173.css"><script id="default-settings" ></script><script src="../../../../static.files/storage-d43fa987303ecbbb.js"></script><script defer src="../../../../static.files/source-script-5cf2e01a42cc9858.js"></script><script defer src="../../../../source-files.js"></script><script defer src="../../../../static.files/main-c55e1eb52e1886b4.js"></script><noscript><link rel="stylesheet" href="../../../../static.files/noscript-13285aec31fa243e.css"></noscript><link rel="alternate icon" type="image/png" href="../../../../static.files/favicon-16x16-8b506e7a72182f1c.png"><link rel="alternate icon" type="image/png" href="../../../../static.files/favicon-32x32-422f7d1d52889060.png"><link rel="icon" type="image/svg+xml" href="../../../../static.files/favicon-2c020d218678b618.svg"></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"></nav><main><div class="width-limiter"><nav class="sub"><a class="sub-logo-container" href="../../../../onnxruntime/index.html"><img class="rust-logo" src="../../../../static.files/rust-logo-151179464ae7ed46.svg" alt="logo"></a><form class="search-form"><span></span><input class="search-input" name="search" aria-label="Run search in the documentation" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"><div id="help-button" title="help" tabindex="-1"><a href="../../../../help.html">?</a></div><div id="settings-menu" tabindex="-1"><a href="../../../../settings.html" title="settings"><img width="22" height="22" alt="Change settings" src="../../../../static.files/wheel-5ec35bf9ca753509.svg"></a></div></form></nav><section id="main-content" class="content"><div class="example-wrap"><pre class="src-line-numbers"><a href="#1" id="1">1</a>
<a href="#2" id="2">2</a>
<a href="#3" id="3">3</a>
<a href="#4" id="4">4</a>
<a href="#5" id="5">5</a>
<a href="#6" id="6">6</a>
<a href="#7" id="7">7</a>
<a href="#8" id="8">8</a>
<a href="#9" id="9">9</a>
<a href="#10" id="10">10</a>
<a href="#11" id="11">11</a>
<a href="#12" id="12">12</a>
<a href="#13" id="13">13</a>
<a href="#14" id="14">14</a>
<a href="#15" id="15">15</a>
<a href="#16" id="16">16</a>
<a href="#17" id="17">17</a>
<a href="#18" id="18">18</a>
<a href="#19" id="19">19</a>
<a href="#20" id="20">20</a>
<a href="#21" id="21">21</a>
<a href="#22" id="22">22</a>
<a href="#23" id="23">23</a>
<a href="#24" id="24">24</a>
<a href="#25" id="25">25</a>
<a href="#26" id="26">26</a>
<a href="#27" id="27">27</a>
<a href="#28" id="28">28</a>
<a href="#29" id="29">29</a>
<a href="#30" id="30">30</a>
<a href="#31" id="31">31</a>
<a href="#32" id="32">32</a>
<a href="#33" id="33">33</a>
<a href="#34" id="34">34</a>
<a href="#35" id="35">35</a>
<a href="#36" id="36">36</a>
<a href="#37" id="37">37</a>
<a href="#38" id="38">38</a>
<a href="#39" id="39">39</a>
<a href="#40" id="40">40</a>
<a href="#41" id="41">41</a>
<a href="#42" id="42">42</a>
<a href="#43" id="43">43</a>
<a href="#44" id="44">44</a>
<a href="#45" id="45">45</a>
<a href="#46" id="46">46</a>
<a href="#47" id="47">47</a>
<a href="#48" id="48">48</a>
<a href="#49" id="49">49</a>
<a href="#50" id="50">50</a>
<a href="#51" id="51">51</a>
<a href="#52" id="52">52</a>
<a href="#53" id="53">53</a>
<a href="#54" id="54">54</a>
<a href="#55" id="55">55</a>
<a href="#56" id="56">56</a>
<a href="#57" id="57">57</a>
<a href="#58" id="58">58</a>
<a href="#59" id="59">59</a>
<a href="#60" id="60">60</a>
<a href="#61" id="61">61</a>
<a href="#62" id="62">62</a>
<a href="#63" id="63">63</a>
<a href="#64" id="64">64</a>
<a href="#65" id="65">65</a>
<a href="#66" id="66">66</a>
<a href="#67" id="67">67</a>
<a href="#68" id="68">68</a>
<a href="#69" id="69">69</a>
<a href="#70" id="70">70</a>
<a href="#71" id="71">71</a>
<a href="#72" id="72">72</a>
<a href="#73" id="73">73</a>
<a href="#74" id="74">74</a>
<a href="#75" id="75">75</a>
<a href="#76" id="76">76</a>
<a href="#77" id="77">77</a>
<a href="#78" id="78">78</a>
<a href="#79" id="79">79</a>
<a href="#80" id="80">80</a>
<a href="#81" id="81">81</a>
<a href="#82" id="82">82</a>
<a href="#83" id="83">83</a>
<a href="#84" id="84">84</a>
<a href="#85" id="85">85</a>
<a href="#86" id="86">86</a>
<a href="#87" id="87">87</a>
<a href="#88" id="88">88</a>
<a href="#89" id="89">89</a>
<a href="#90" id="90">90</a>
<a href="#91" id="91">91</a>
<a href="#92" id="92">92</a>
<a href="#93" id="93">93</a>
<a href="#94" id="94">94</a>
<a href="#95" id="95">95</a>
<a href="#96" id="96">96</a>
<a href="#97" id="97">97</a>
<a href="#98" id="98">98</a>
<a href="#99" id="99">99</a>
<a href="#100" id="100">100</a>
<a href="#101" id="101">101</a>
<a href="#102" id="102">102</a>
<a href="#103" id="103">103</a>
<a href="#104" id="104">104</a>
<a href="#105" id="105">105</a>
<a href="#106" id="106">106</a>
<a href="#107" id="107">107</a>
</pre><pre class="rust"><code><span class="doccomment">//! Module defining object detection and image segmentation  models available to download.
//!
//! See [https://github.com/onnx/models#object_detection](https://github.com/onnx/models#object_detection)

</span><span class="comment">// Acronyms are specific ONNX model names and contains upper cases
</span><span class="attr">#![allow(clippy::upper_case_acronyms)]

</span><span class="kw">use </span><span class="kw">crate</span>::download::{vision::Vision, AvailableOnnxModel, ModelUrl};

<span class="doccomment">/// Object Detection &amp; Image Segmentation
///
/// &gt; Object detection models detect the presence of multiple objects in an image and segment out areas of the
/// &gt; image where the objects are detected. Semantic segmentation models partition an input image by labeling each pixel
/// &gt; into a set of pre-defined categories.
///
/// Source: [https://github.com/onnx/models#object_detection](https://github.com/onnx/models#object_detection)
</span><span class="attr">#[derive(Debug, Clone)]
</span><span class="kw">pub enum </span>ObjectDetectionImageSegmentation {
    <span class="doccomment">/// A real-time CNN for object detection that detects 20 different classes. A smaller version of the
    /// more complex full YOLOv2 network.
    ///
    /// Variant downloaded: ONNX Version 1.3 with Opset Version 8.
    </span>TinyYoloV2,
    <span class="doccomment">/// Single Stage Detector: real-time CNN for object detection that detects 80 different classes.
    ///
    /// Variant downloaded: ONNX Version 1.5 with Opset Version 10.
    </span>Ssd,
    <span class="doccomment">/// A variant of MobileNet that uses the Single Shot Detector (SSD) model framework. The model detects 80
    /// different object classes and locates up to 10 objects in an image.
    ///
    /// Variant downloaded: ONNX Version 1.7.0 with Opset Version 10.
    </span>SSDMobileNetV1,
    <span class="doccomment">/// Increases efficiency from R-CNN by connecting a RPN with a CNN to create a single, unified network for
    /// object detection that detects 80 different classes.
    ///
    /// Variant downloaded: ONNX Version 1.5 with Opset Version 10.
    </span>FasterRcnn,
    <span class="doccomment">/// A real-time neural network for object instance segmentation that detects 80 different classes. Extends
    /// Faster R-CNN as each of the 300 elected ROIs go through 3 parallel branches of the network: label
    /// prediction, bounding box prediction and mask prediction.
    ///
    /// Variant downloaded: ONNX Version 1.5 with Opset Version 10.
    </span>MaskRcnn,
    <span class="doccomment">/// A real-time dense detector network for object detection that addresses class imbalance through Focal Loss.
    /// RetinaNet is able to match the speed of previous one-stage detectors and defines the state-of-the-art in
    /// two-stage detectors (surpassing R-CNN).
    ///
    /// Variant downloaded: ONNX Version 1.6.0 with Opset Version 9.
    </span>RetinaNet,
    <span class="doccomment">/// A CNN model for real-time object detection system that can detect over 9000 object categories. It uses a
    /// single network evaluation, enabling it to be more than 1000x faster than R-CNN and 100x faster than
    /// Faster R-CNN.
    ///
    /// Variant downloaded: ONNX Version 1.3 with Opset Version 8.
    </span>YoloV2,
    <span class="doccomment">/// A CNN model for real-time object detection system that can detect over 9000 object categories. It uses
    /// a single network evaluation, enabling it to be more than 1000x faster than R-CNN and 100x faster than
    /// Faster R-CNN. This model is trained with COCO dataset and contains 80 classes.
    ///
    /// Variant downloaded: ONNX Version 1.5 with Opset Version 9.
    </span>YoloV2Coco,
    <span class="doccomment">/// A deep CNN model for real-time object detection that detects 80 different classes. A little bigger than
    /// YOLOv2 but still very fast. As accurate as SSD but 3 times faster.
    ///
    /// Variant downloaded: ONNX Version 1.5 with Opset Version 10.
    </span>YoloV3,
    <span class="doccomment">/// A smaller version of YOLOv3 model.
    ///
    /// Variant downloaded: ONNX Version 1.6 with Opset Version 11.
    </span>TinyYoloV3,
    <span class="doccomment">/// Optimizes the speed and accuracy of object detection. Two times faster than EfficientDet. It improves
    /// YOLOv3&#39;s AP and FPS by 10% and 12%, respectively, with mAP50 of 52.32 on the COCO 2017 dataset and
    /// FPS of 41.7 on Tesla 100.
    ///
    /// Variant downloaded: ONNX Version 1.6 with Opset Version 11.
    </span>YoloV4,
    <span class="doccomment">/// Deep CNN based pixel-wise semantic segmentation model with &gt;80% mIOU (mean Intersection Over Union).
    /// Trained on cityscapes dataset, which can be effectively implemented in self driving vehicle systems.
    ///
    /// Variant downloaded: ONNX Version 1.2.2 with Opset Version 7.
    </span>Duc,
}

<span class="kw">impl </span>ModelUrl <span class="kw">for </span>ObjectDetectionImageSegmentation {
    <span class="kw">fn </span>fetch_url(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;static </span>str {
        <span class="kw">match </span><span class="self">self </span>{
            ObjectDetectionImageSegmentation::TinyYoloV2 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/tiny-yolov2/model/tinyyolov2-8.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::Ssd =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/ssd/model/ssd-10.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::SSDMobileNetV1 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/ssd-mobilenetv1/model/ssd_mobilenet_v1_10.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::FasterRcnn =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/faster-rcnn/model/FasterRCNN-10.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::MaskRcnn =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/mask-rcnn/model/MaskRCNN-10.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::RetinaNet =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/retinanet/model/retinanet-9.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::YoloV2 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/yolov2/model/yolov2-voc-8.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::YoloV2Coco =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/yolov2-coco/model/yolov2-coco-9.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::YoloV3 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/yolov3/model/yolov3-10.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::TinyYoloV3 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/tiny-yolov3/model/tiny-yolov3-11.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::YoloV4 =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/yolov4/model/yolov4.onnx&quot;</span>,
            ObjectDetectionImageSegmentation::Duc =&gt; <span class="string">&quot;https://github.com/onnx/models/raw/main/vision/object_detection_segmentation/duc/model/ResNet101-DUC-7.onnx&quot;</span>,
        }
    }
}

<span class="kw">impl </span>From&lt;ObjectDetectionImageSegmentation&gt; <span class="kw">for </span>AvailableOnnxModel {
    <span class="kw">fn </span>from(model: ObjectDetectionImageSegmentation) -&gt; <span class="self">Self </span>{
        AvailableOnnxModel::Vision(Vision::ObjectDetectionImageSegmentation(model))
    }
}
</code></pre></div>
</section></div></main><div id="rustdoc-vars" data-root-path="../../../../" data-static-root-path="../../../../static.files/" data-current-crate="onnxruntime" data-themes="" data-resource-suffix="" data-rustdoc-version="1.67.0 (fc594f156 2023-01-24)" data-search-js="search-444266647c4dba98.js" data-settings-js="settings-bebeae96e00e4617.js" data-settings-css="settings-af96d9e2fc13e081.css" ></div></body></html>